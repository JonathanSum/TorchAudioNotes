{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Generate text with recurrent networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPkV/l/gBMiIE3MJYV6ka2l",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanSum/TorchAudio_and_TorchTextNotes/blob/main/Generate_text_with_recurrent_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qdGHjK7FE0ij",
        "outputId": "c649d7e6-d5ba-4190-ba14-455a945b99b4"
      },
      "source": [
        "!pip install -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim==3.8.3 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1)) (3.8.3)\n",
            "Requirement already satisfied: huggingface==0.0.1 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 2)) (0.0.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (3.2.2)\n",
            "Requirement already satisfied: nltk==3.5 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (3.5)\n",
            "Requirement already satisfied: numpy==1.18.5 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 5)) (1.18.5)\n",
            "Requirement already satisfied: opencv-python==4.5.1.48 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 6)) (4.5.1.48)\n",
            "Requirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 8)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 9)) (1.4.1)\n",
            "Requirement already satisfied: torch==1.8.1 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 10)) (1.8.1)\n",
            "Requirement already satisfied: torchaudio==0.8.1 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 11)) (0.8.1)\n",
            "Requirement already satisfied: torchinfo==0.0.8 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 12)) (0.0.8)\n",
            "Requirement already satisfied: torchtext==0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (0.9.1)\n",
            "Requirement already satisfied: torchvision==0.9.1 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 14)) (0.9.1)\n",
            "Requirement already satisfied: transformers==4.3.3 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (4.3.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1)) (5.1.0)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (0.0.45)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (3.0.12)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (4.6.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (21.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (0.10.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (3.5.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (2.10)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikUh1tJiE13N"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/torchnlp.py"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5s2C8T0_FHkm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1e1d4942-b5d4-4afc-a7d3-07707d4eebc7"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "import numpy as np\n",
        "from torchnlp import *\n",
        "train_dataset,test_dataset,classes,vocab = load_dataset()"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n",
            "Building vocab...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8XgFfo57OPpC",
        "outputId": "6294711e-c10a-447c-edd3-7816686f81a9"
      },
      "source": [
        "def char_tokenizer(words):\n",
        "    return list(words) #[word for word in words]\n",
        "\n",
        "counter = collections.Counter()\n",
        "for (label, line) in train_dataset:\n",
        "    counter.update(char_tokenizer(line))\n",
        "vocab = torchtext.vocab.Vocab(counter)\n",
        "\n",
        "vocab_size = len(vocab)\n",
        "print(f\"Vocabulary size = {vocab_size}\")\n",
        "print(f\"Encoding of 'a' is {vocab.stoi['a']}\")\n",
        "print(f\"Character with code 13 is {vocab.itos[13]}\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Vocabulary size = 84\n",
            "Encoding of 'a' is 4\n",
            "Character with code 13 is h\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3MlbFZ9gQCW0",
        "outputId": "079261cb-18c4-4a36-b0ef-362e492ed280"
      },
      "source": [
        "vocab.stoi['a']"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m67-aPmdQMjS"
      },
      "source": [
        "# vocab.stoi"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f2sUpCbM1czs",
        "outputId": "34005745-1081-43bf-d1e1-a301b82f70cc"
      },
      "source": [
        "def enc(x):\n",
        "    return torch.LongTensor(encode(x,voc=vocab,tokenizer=char_tokenizer))\n",
        "\n",
        "enc(train_dataset[0][1])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([43,  4, 11, 11,  2, 26,  5, 23,  2, 38,  3,  4, 10,  9,  2, 31, 11,  4,\n",
              "        21,  2, 38,  4, 14, 25,  2, 34,  8,  5,  6,  2,  5, 13,  3,  2, 38, 11,\n",
              "         4, 14, 25,  2, 55, 37,  3, 15,  5,  3, 10,  9, 56,  2, 37,  3, 15,  5,\n",
              "         3, 10,  9,  2, 29,  2, 26, 13,  6, 10,  5, 29,  9,  3, 11, 11,  3, 10,\n",
              "         9, 27,  2, 43,  4, 11, 11,  2, 26,  5, 10,  3,  3,  5, 58,  9,  2, 12,\n",
              "        21,  7,  8, 12, 11,  7,  8, 18, 61, 22,  4,  8, 12,  2,  6, 19,  2, 15,\n",
              "        11,  5, 10,  4, 29, 14, 20,  8,  7, 14,  9, 27,  2,  4, 10,  3,  2,  9,\n",
              "         3,  3,  7,  8, 18,  2, 18, 10,  3,  3,  8,  2,  4, 18,  4,  7,  8, 23])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCtF5ulTF7Ia",
        "outputId": "091499b0-d20d-40e8-e9f3-f13b62587ffe"
      },
      "source": [
        "nchars = 100\n",
        "\n",
        "def get_batch(s,nchars=nchars):\n",
        "    ins = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
        "    outs = torch.zeros(len(s)-nchars,nchars,dtype=torch.long,device=device)\n",
        "    for i in range(len(s)-nchars):\n",
        "        ins[i] = enc(s[i:i+nchars])\n",
        "        outs[i] = enc(s[i+1:i+nchars+1])\n",
        "    return ins,outs\n",
        "\n",
        "get_batch(train_dataset[0][1])"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[43,  4, 11,  ..., 18, 61, 22],\n",
              "         [ 4, 11, 11,  ..., 61, 22,  4],\n",
              "         [11, 11,  2,  ..., 22,  4,  8],\n",
              "         ...,\n",
              "         [37,  3, 15,  ...,  4, 18,  4],\n",
              "         [ 3, 15,  5,  ..., 18,  4,  7],\n",
              "         [15,  5,  3,  ...,  4,  7,  8]], device='cuda:0'),\n",
              " tensor([[ 4, 11, 11,  ..., 61, 22,  4],\n",
              "         [11, 11,  2,  ..., 22,  4,  8],\n",
              "         [11,  2, 26,  ...,  4,  8, 12],\n",
              "         ...,\n",
              "         [ 3, 15,  5,  ..., 18,  4,  7],\n",
              "         [15,  5,  3,  ...,  4,  7,  8],\n",
              "         [ 5,  3, 10,  ...,  7,  8, 23]], device='cuda:0'))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgILW2nPF9Wq"
      },
      "source": [
        "class LSTMGenerator(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.rnn = torch.nn.LSTM(vocab_size,hidden_dim,batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, vocab_size)\n",
        "\n",
        "    def forward(self, x, s=None):\n",
        "        x = torch.nn.functional.one_hot(x,vocab_size).to(torch.float32)\n",
        "        x,s = self.rnn(x,s)\n",
        "        return self.fc(x),s"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PDIo7Ub6F31G"
      },
      "source": [
        "def generate(net,size=100,start='today '):\n",
        "        chars = list(start)\n",
        "        out, s = net(enc(chars).view(1,-1).to(device))\n",
        "        for i in range(size):\n",
        "            nc = torch.argmax(out[0][-1])\n",
        "            chars.append(vocab.itos[nc])\n",
        "            out, s = net(nc.view(1,-1),s)\n",
        "        return ''.join(chars)"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        },
        "id": "QEX9VIK5F-Gs",
        "outputId": "44e08b46-f8df-4645-c85d-9cbcaf83a09b"
      },
      "source": [
        "net = LSTMGenerator(vocab_size,64).to(device)\n",
        "\n",
        "samples_to_train = 20000\n",
        "optimizer = torch.optim.Adam(net.parameters(),0.01)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "net.train()\n",
        "for i,x in enumerate(train_dataset):\n",
        "    # x[0] is class label, x[1] is text\n",
        "    if len(x[1])-nchars<10:\n",
        "        continue\n",
        "    samples_to_train-=1\n",
        "    if not samples_to_train: break\n",
        "    text_in, text_out = get_batch(x[1])\n",
        "    optimizer.zero_grad()\n",
        "    out,s = net(text_in)\n",
        "    loss = torch.nn.functional.cross_entropy(out.view(-1,vocab_size),text_out.flatten()) #cross_entropy(out,labels)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    if i%1000==0:\n",
        "        print(f\"Current loss = {loss.item()}\")\n",
        "        print(generate(net))"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Current loss = 4.431696891784668\n",
            "today ****************************************************************************************************\n",
            "Current loss = 2.1639821529388428\n",
            "today and and and and and and and and and and and and and and and and and and and and and and and and and \n",
            "Current loss = 1.6688047647476196\n",
            "today on Tuesday of the burding a deater and a dead a dead a dead a dead a dead a dead a dead a dead a dea\n",
            "Current loss = 2.3510375022888184\n",
            "today to the second the second the second the second the second the second the second the second the secon\n",
            "Current loss = 1.6809459924697876\n",
            "today to the start to the start to the start to the start to the start to the start to the start to the st\n",
            "Current loss = 1.724931001663208\n",
            "today the second the U.S. company a proves of the U.S. company a proves of the U.S. company a proves of th\n",
            "Current loss = 2.0154306888580322\n",
            "today the second the second the second the second the second the second the second the second the second t\n",
            "Current loss = 1.9550042152404785\n",
            "today and and and and and and and and and and and and and and and and and and and and and and and and and \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-41-24b031cab97e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0msamples_to_train\u001b[0m\u001b[0;34m-=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msamples_to_train\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0mtext_in\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_out\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext_in\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-38-f4e0a3433ff5>\u001b[0m in \u001b[0;36mget_batch\u001b[0;34m(s, nchars)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnchars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnchars\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mnchars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mins\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnchars\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mouts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mnchars\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mins\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jYDPnVDYGBLn"
      },
      "source": [
        "o1 = enc(\"happy sugar life\")"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRRWF3eReIiI",
        "outputId": "56a0bf4a-41c9-4e33-d816-fedc9ff61e52"
      },
      "source": [
        "o1.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WPwqFQgeDsn",
        "outputId": "e48264c9-d2a1-45e0-94d6-1c561b2bb42c"
      },
      "source": [
        "o1.view(1,-1).shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "9aFk7kMKe6SB",
        "outputId": "241e4285-574f-4a0e-bb11-813c90f7e7ca"
      },
      "source": [
        "generate(net)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'today the security the security the security the security the security the security the security the secur'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbeZhpXfeuSy"
      },
      "source": [
        "o2, s = net(enc(\"today i\").view(1,-1).to(device))"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p292LW7Wktdk"
      },
      "source": [
        "Input has 7 chars, which is \"today i\". Out length will be same too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uPR24-chfxwm",
        "outputId": "2354ce93-5b8c-40ef-dfd0-45ec4df7ef44"
      },
      "source": [
        "o2.shape"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 7, 84])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4EXzVcIfyeP",
        "outputId": "ba6730e7-9b91-46fe-a7f2-83fdf7d06cff"
      },
      "source": [
        "vocab_size"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "84"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_D_0bwVrk0bA"
      },
      "source": [
        "o2[0][-1] means we have a 1 by 7 by 84 tensor, and we will pick one char from the 84 vacab(s). We will use argmax to pick it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YE_YWCsEf0W3"
      },
      "source": [
        "ol=[]\n",
        "nc1 = torch.argmax(o2[0][-1])\n",
        "ol.append(vocab.itos[nc1])"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FgJZt36FgRt-",
        "outputId": "a7ab9816-a165-474f-eec2-00b0e0559390"
      },
      "source": [
        "ol"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['n']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UH0oCkndjZ0F",
        "outputId": "ee9caafa-9375-48e8-cfe7-40bc2fea61f1"
      },
      "source": [
        "def generate_soft(net,size=100,start='today ',temperature=1.0):\n",
        "        chars = list(start)\n",
        "        out, s = net(enc(chars).view(1,-1).to(device))\n",
        "        for i in range(size):\n",
        "            #nc = torch.argmax(out[0][-1])\n",
        "            out_dist = out[0][-1].div(temperature).exp()\n",
        "            nc = torch.multinomial(out_dist,1)[0]\n",
        "            chars.append(vocab.itos[nc])\n",
        "            out, s = net(nc.view(1,-1),s)\n",
        "        return ''.join(chars)\n",
        "    \n",
        "for i in [0.3,0.8,1.0,1.3,1.8]:\n",
        "    print(f\"--- Temperature = {i}\\n{generate_soft(net,size=300,start='Today ',temperature=i)}\\n\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--- Temperature = 0.3\n",
            "Today for a to the second a group a the first the security security ather the large to the the second on the world a to security state the security in the security of the the the serving the security to the battle security of the as the for a securien the first the security week have and the second the ma\n",
            "\n",
            "--- Temperature = 0.8\n",
            "Today wouk Inc. use's have allow potugh internet of OKroubin  quot; the tocks ros work and procend green and a the So maghing contrame strep of the signed almert of 28 protet of the athrrace to help group back as the feater tech The Stell heading the mattee the Coran Xitional ting Sottralid Heal loneter m\n",
            "\n",
            "--- Temperature = 1.0\n",
            "Today Europer rised a naval Alymn Artate cent dumer whickalf and and Hepent Is pumico and  #3954-give pitting to end to houeged arrink fould atha the Ahio IF Mair widesiona economainisthe 17 0-hime striat at ATHENS -- death by after Korent Britakh Susday an a parma has not includitial deball mighter a the\n",
            "\n",
            "--- Temperature = 1.3\n",
            "Today West third end than cappity in 9004,00's increadenferonary induled the 2006 appenfit-Qou to syginhtem thavan 3.0, had rop intern Llas Patting neeks amwait a slich, Jamio. E valefhetionwet bet quarp the oring5of bagitifignt dot wat intheng arry \\$00060.U. (PDvausk, Eitta A court comtrimiastwoun liger\n",
            "\n",
            "--- Temperature = 1.8\n",
            "Today actales cut (MRJDYQ6 (Q5, Plez. Rre-Erlieve -Spar CH IrtL 61-3N  grip fushinith ongsininf, letsing-togalo isdost \\$1DTH outher prarints 1\"5\\fightion 0J'sklsKliemanty-vunelek;RXOR-O.MD/ktoigg Rrex-en HD, PRFKS. 9:5,50/A&gt;\\Netwalket JsK's'? in 1stereef.cest c.NVQ, NAFCr/S&lt;. 6X32ImE) -t Jr1J,s sli\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}