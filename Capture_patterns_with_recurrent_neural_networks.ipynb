{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Capture patterns with recurrent neural networks.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPmBlhpi3Xxud7GTvybsnOw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JonathanSum/TorchAudio_and_TorchTextNotes/blob/main/Capture_patterns_with_recurrent_neural_networks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hH_1rrEBEwvM",
        "outputId": "cffb7030-0541-47e7-f0e2-7672a067004b"
      },
      "source": [
        "!pip install -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting gensim==3.8.3\n",
            "  Downloading gensim-3.8.3-cp37-cp37m-manylinux1_x86_64.whl (24.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 24.2 MB 1.7 MB/s \n",
            "\u001b[?25hCollecting huggingface==0.0.1\n",
            "  Downloading huggingface-0.0.1-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (3.2.2)\n",
            "Collecting nltk==3.5\n",
            "  Downloading nltk-3.5.zip (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 33.5 MB/s \n",
            "\u001b[?25hCollecting numpy==1.18.5\n",
            "  Downloading numpy-1.18.5-cp37-cp37m-manylinux1_x86_64.whl (20.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 20.1 MB 1.4 MB/s \n",
            "\u001b[?25hCollecting opencv-python==4.5.1.48\n",
            "  Downloading opencv_python-4.5.1.48-cp37-cp37m-manylinux2014_x86_64.whl (50.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 50.4 MB 19 kB/s \n",
            "\u001b[?25hRequirement already satisfied: Pillow==7.1.2 in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 7)) (7.1.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 8)) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from -r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 9)) (1.4.1)\n",
            "Collecting torch==1.8.1\n",
            "  Downloading torch-1.8.1-cp37-cp37m-manylinux1_x86_64.whl (804.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 804.1 MB 2.8 kB/s \n",
            "\u001b[?25hCollecting torchaudio==0.8.1\n",
            "  Downloading torchaudio-0.8.1-cp37-cp37m-manylinux1_x86_64.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 27.3 MB/s \n",
            "\u001b[?25hCollecting torchinfo==0.0.8\n",
            "  Downloading torchinfo-0.0.8-py3-none-any.whl (16 kB)\n",
            "Collecting torchtext==0.9.1\n",
            "  Downloading torchtext-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (7.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.1 MB 39.5 MB/s \n",
            "\u001b[?25hCollecting torchvision==0.9.1\n",
            "  Downloading torchvision-0.9.1-cp37-cp37m-manylinux1_x86_64.whl (17.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 17.4 MB 203 kB/s \n",
            "\u001b[?25hCollecting transformers==4.3.3\n",
            "  Downloading transformers-4.3.3-py3-none-any.whl (1.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.9 MB 38.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1)) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim==3.8.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 1)) (5.1.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (1.0.1)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from nltk==3.5->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 4)) (4.41.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.8.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 10)) (3.7.4.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (3.0.12)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 38.7 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.45-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 38.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (4.6.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (2.4.7)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 3)) (0.10.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.3.3->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 15)) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchtext==0.9.1->-r https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/requirements.txt (line 13)) (2.10)\n",
            "Building wheels for collected packages: nltk\n",
            "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nltk: filename=nltk-3.5-py3-none-any.whl size=1434689 sha256=32feebaf507bb0bbd9daf4c4f86b74342c97d66ba9c4c8819ca92c5b88853a55\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/6c/46/a1865e7ba706b3817f5d1b2ff7ce8996aabdd0d03d47ba0266\n",
            "Successfully built nltk\n",
            "Installing collected packages: numpy, torch, tokenizers, sacremoses, transformers, torchvision, torchtext, torchinfo, torchaudio, opencv-python, nltk, huggingface, gensim\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.9.0+cu102\n",
            "    Uninstalling torch-1.9.0+cu102:\n",
            "      Successfully uninstalled torch-1.9.0+cu102\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.10.0+cu102\n",
            "    Uninstalling torchvision-0.10.0+cu102:\n",
            "      Successfully uninstalled torchvision-0.10.0+cu102\n",
            "  Attempting uninstall: torchtext\n",
            "    Found existing installation: torchtext 0.10.0\n",
            "    Uninstalling torchtext-0.10.0:\n",
            "      Successfully uninstalled torchtext-0.10.0\n",
            "  Attempting uninstall: opencv-python\n",
            "    Found existing installation: opencv-python 4.1.2.30\n",
            "    Uninstalling opencv-python-4.1.2.30:\n",
            "      Successfully uninstalled opencv-python-4.1.2.30\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "  Attempting uninstall: gensim\n",
            "    Found existing installation: gensim 3.6.0\n",
            "    Uninstalling gensim-3.6.0:\n",
            "      Successfully uninstalled gensim-3.6.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.5.0 requires numpy~=1.19.2, but you have numpy 1.18.5 which is incompatible.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed gensim-3.8.3 huggingface-0.0.1 nltk-3.5 numpy-1.18.5 opencv-python-4.5.1.48 sacremoses-0.0.45 tokenizers-0.10.3 torch-1.8.1 torchaudio-0.8.1 torchinfo-0.0.8 torchtext-0.9.1 torchvision-0.9.1 transformers-4.3.3\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdmfca15E_Hx"
      },
      "source": [
        "!wget -q https://raw.githubusercontent.com/MicrosoftDocs/pytorchfundamentals/main/nlp-pytorch/torchnlp.py"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sivWpCQaEl_z",
        "outputId": "7142bd3a-d387-47a9-873a-568ae5c320aa"
      },
      "source": [
        "import torch\n",
        "import torchtext\n",
        "from torchnlp import *\n",
        "train_dataset, test_dataset, classes, vocab = load_dataset()\n",
        "vocab_size = len(vocab)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "train.csv: 29.5MB [00:00, 82.3MB/s]\n",
            "test.csv: 1.86MB [00:00, 27.3MB/s]                  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Building vocab...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vs-u447NFC9t"
      },
      "source": [
        "class RNNClassifier(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
        "        self.rnn = torch.nn.RNN(embed_dim,hidden_dim,batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_class)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.embedding(x)\n",
        "        x,h = self.rnn(x)\n",
        "        return self.fc(x.mean(dim=1))"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-fEoaxP5Fkj_",
        "outputId": "063bbee7-1d3d-4815-ff46-8bb0c35e470a"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=padify, shuffle=True)\n",
        "net = RNNClassifier(vocab_size,64,32,len(classes)).to(device)\n",
        "train_epoch(net,train_loader, lr=0.001)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3200: acc=0.308125\n",
            "6400: acc=0.38390625\n",
            "9600: acc=0.46239583333333334\n",
            "12800: acc=0.51453125\n",
            "16000: acc=0.554375\n",
            "19200: acc=0.5868229166666666\n",
            "22400: acc=0.6121428571428571\n",
            "25600: acc=0.63484375\n",
            "28800: acc=0.6536111111111111\n",
            "32000: acc=0.66903125\n",
            "35200: acc=0.6814772727272728\n",
            "38400: acc=0.6933333333333334\n",
            "41600: acc=0.7032932692307692\n",
            "44800: acc=0.7128125\n",
            "48000: acc=0.7207708333333334\n",
            "51200: acc=0.7282421875\n",
            "54400: acc=0.7349080882352941\n",
            "57600: acc=0.7407465277777778\n",
            "60800: acc=0.7474177631578948\n",
            "64000: acc=0.75178125\n",
            "67200: acc=0.7563690476190477\n",
            "70400: acc=0.7613068181818182\n",
            "73600: acc=0.7660054347826087\n",
            "76800: acc=0.7701953125\n",
            "80000: acc=0.77325\n",
            "83200: acc=0.7772836538461538\n",
            "86400: acc=0.7810185185185186\n",
            "89600: acc=0.7841517857142857\n",
            "92800: acc=0.7873706896551724\n",
            "96000: acc=0.79046875\n",
            "99200: acc=0.7931552419354839\n",
            "102400: acc=0.795859375\n",
            "105600: acc=0.7985227272727272\n",
            "108800: acc=0.801139705882353\n",
            "112000: acc=0.8033303571428572\n",
            "115200: acc=0.8056510416666667\n",
            "118400: acc=0.8077111486486487\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.03282213745117187, 0.8085833333333333)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7yTh0qX2Y_V"
      },
      "source": [
        "def pad_length(b):\n",
        "    # build vectorized sequence\n",
        "    v = [encode(x[1]) for x in b]\n",
        "    # compute max length of a sequence in this minibatch and length sequence itself\n",
        "    len_seq = list(map(len,v))\n",
        "    l = max(len_seq)\n",
        "    return ( # tuple of three tensors - labels, padded features, length sequence\n",
        "        torch.LongTensor([t[0]-1 for t in b]),\n",
        "        torch.stack([torch.nn.functional.pad(torch.tensor(t),(0,l-len(t)),mode='constant',value=0) for t in v]),\n",
        "        torch.tensor(len_seq)\n",
        "    )\n",
        "\n",
        "train_loader_len = torch.utils.data.DataLoader(train_dataset, batch_size=16, collate_fn=pad_length, shuffle=True)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YdvoFWYDK_bx"
      },
      "source": [
        "t1 = torch.tensor([[1,2,3,4,5],\n",
        " [6,7,8,0,0],\n",
        " [9,0,0,0,0]])"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bPsIo97pTkXU",
        "outputId": "4ff6be60-770a-43be-8f6e-140d2ca24039"
      },
      "source": [
        "t1.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([3, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhC2IK62d1wF"
      },
      "source": [
        "class LSTMPackClassifier(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
        "        self.embedding.weight.data = torch.randn_like(self.embedding.weight.data)-0.5\n",
        "        self.rnn = torch.nn.LSTM(embed_dim,hidden_dim,batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_class)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.embedding(x)\n",
        "        pad_x = torch.nn.utils.rnn.pack_padded_sequence(x,lengths,batch_first=True,enforce_sorted=False)\n",
        "        pad_x,(h,c) = self.rnn(pad_x)\n",
        "        x, _ = torch.nn.utils.rnn.pad_packed_sequence(pad_x,batch_first=True)\n",
        "        return self.fc(h[-1])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EiokclOeTk7c",
        "outputId": "b9b089f9-7241-493a-eeac-0d947e0e629e"
      },
      "source": [
        "net = LSTMPackClassifier(vocab_size,64,32,len(classes)).to(device)\n",
        "train_epoch_emb(net,train_loader_len, lr=0.001,use_pack_sequence=True)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3200: acc=0.288125\n",
            "6400: acc=0.3459375\n",
            "9600: acc=0.4060416666666667\n",
            "12800: acc=0.454609375\n",
            "16000: acc=0.49625\n",
            "19200: acc=0.5338020833333333\n",
            "22400: acc=0.5651339285714285\n",
            "25600: acc=0.591328125\n",
            "28800: acc=0.614375\n",
            "32000: acc=0.634625\n",
            "35200: acc=0.6518181818181819\n",
            "38400: acc=0.6684635416666667\n",
            "41600: acc=0.6822355769230769\n",
            "44800: acc=0.6944642857142858\n",
            "48000: acc=0.70475\n",
            "51200: acc=0.71517578125\n",
            "54400: acc=0.72375\n",
            "57600: acc=0.7313020833333334\n",
            "60800: acc=0.7389473684210527\n",
            "64000: acc=0.745671875\n",
            "67200: acc=0.7520238095238095\n",
            "70400: acc=0.7577840909090909\n",
            "73600: acc=0.7632472826086957\n",
            "76800: acc=0.7682552083333334\n",
            "80000: acc=0.7732125\n",
            "83200: acc=0.7774158653846154\n",
            "86400: acc=0.7815972222222223\n",
            "89600: acc=0.7852678571428572\n",
            "92800: acc=0.7890301724137931\n",
            "96000: acc=0.79246875\n",
            "99200: acc=0.7957762096774194\n",
            "102400: acc=0.799169921875\n",
            "105600: acc=0.8019886363636364\n",
            "108800: acc=0.8045404411764706\n",
            "112000: acc=0.8072946428571428\n",
            "115200: acc=0.8098784722222222\n",
            "118400: acc=0.8124831081081081\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.02992859903971354, 0.8136)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iSEF2Kdfo0l"
      },
      "source": [
        "class LSTMPackClassifier1(torch.nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_class):\n",
        "        super().__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding = torch.nn.Embedding(vocab_size, embed_dim)\n",
        "        self.embedding.weight.data = torch.randn_like(self.embedding.weight.data)-0.5\n",
        "        self.rnn = torch.nn.LSTM(embed_dim,hidden_dim,batch_first=True)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, num_class)\n",
        "\n",
        "    def forward(self, x, lengths):\n",
        "        batch_size = x.size(0)\n",
        "        x = self.embedding(x)\n",
        "        pad_x = torch.nn.utils.rnn.pack_padded_sequence(x,lengths,batch_first=True,enforce_sorted=False)\n",
        "        pad_x,(h,c) = self.rnn(pad_x)\n",
        "        return self.fc(h[-1])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uig4OL7fufY",
        "outputId": "580150ce-5405-478a-c6a6-46596fbc2df0"
      },
      "source": [
        "net1 = LSTMPackClassifier1(vocab_size,64,32,len(classes)).to(device)\n",
        "train_epoch_emb(net1,train_loader_len, lr=0.001,use_pack_sequence=True)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3200: acc=0.285\n",
            "6400: acc=0.34578125\n",
            "9600: acc=0.40270833333333333\n",
            "12800: acc=0.458671875\n",
            "16000: acc=0.50625\n",
            "19200: acc=0.5458333333333333\n",
            "22400: acc=0.5781696428571429\n",
            "25600: acc=0.60625\n",
            "28800: acc=0.6280555555555556\n",
            "32000: acc=0.64803125\n",
            "35200: acc=0.665\n",
            "38400: acc=0.679765625\n",
            "41600: acc=0.6927163461538461\n",
            "44800: acc=0.7044196428571429\n",
            "48000: acc=0.7151875\n",
            "51200: acc=0.72427734375\n",
            "54400: acc=0.7320036764705883\n",
            "57600: acc=0.739375\n",
            "60800: acc=0.7466776315789474\n",
            "64000: acc=0.75315625\n",
            "67200: acc=0.7592410714285714\n",
            "70400: acc=0.7650710227272727\n",
            "73600: acc=0.770366847826087\n",
            "76800: acc=0.7747526041666667\n",
            "80000: acc=0.7792875\n",
            "83200: acc=0.7832932692307693\n",
            "86400: acc=0.7874652777777778\n",
            "89600: acc=0.7912165178571429\n",
            "92800: acc=0.7949030172413794\n",
            "96000: acc=0.7981770833333334\n",
            "99200: acc=0.8014012096774193\n",
            "102400: acc=0.804140625\n",
            "105600: acc=0.8068276515151516\n",
            "108800: acc=0.8093290441176471\n",
            "112000: acc=0.8119375\n",
            "115200: acc=0.81421875\n",
            "118400: acc=0.8166638513513513\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.02971452433268229, 0.81755)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    }
  ]
}